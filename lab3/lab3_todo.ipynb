{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Students\n",
                "- Student 1: <span style=\"color:green\">NIA - Name and Surname</span>\n",
                "- Student 2: <span style=\"color:green\">NIA - Name and Surname</span>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lab 3: The geometry of two views and 3D reconstruction\n",
                "\n",
                "In this lab session, we are going to compute the 3D position of a pair of cameras and a set of keypoints.  For this, we will first compute correspondences between the two images.  Then, we will robustly compute the Fundamental matrix that encodes the geometry of the two views. From the Fundamental matrix and the camera calibration matrix -- that we learnt to estimate in the third lab session -- we will get the Essential matrix, which encodes the relative motion between the two cameras.  We will then compute the motion between the cameras and, finally, triangulate the matched keypoints to obtain their 3D position.\n",
                "\n",
                "The goals of this lab assignment are the following:\n",
                "\n",
                "- How to estimate the fundamental matrix that relates two images, corresponding to two different views of the same scene, given a set of correspondences between them. In particular, we will use the 8-point algorithm.\n",
                "\n",
                "- How to compute the relative pose of two calibrated cameras\n",
                "\n",
                "- How to triangulate point matches to reconstruct their 3D position.\n",
                "\n",
                "You will have to answer the questions and complete the provided code when necessary as required. **You must deliver the completed (and executed) ipynb file, including the answers to the questions (please make clear visually what it is answer, either preceding it by ANSWER and/or changing its color).**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <strong>\ud83c\udfa5 Introduction</strong>:\n",
                "  <ul>\n",
                "    <li>Provide an overall explanation of the lab. Describe the goals of the lab clearly.</li>\n",
                "    <li>State the problem you were trying to solve or explore in this lab.</li>\n",
                "  </ul>\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **1. Estimation of the fundamental matrix**\n",
                "\n",
                "### **1.1 The 8-point algorithm**\n",
                "\n",
                "The first task is to create the function that estimates the fundamental matrix given a set of point correspondences between a pair of images. We provide the incomplete function `fundamental_matrix` that computes,\n",
                "with the normalised 8-point algorithm, an estimation of the Fundamental matrix\n",
                "from a set of tentative point correspondences.  \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "**Q1.** Complete the function `fundamental_matrix` below.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "import math\n",
                "import random\n",
                "import sys\n",
                "\n",
                "import cv2\n",
                "import numpy as np\n",
                "import plotly.graph_objects as go\n",
                "import seaborn as sns\n",
                "from IPython.display import Markdown\n",
                "from matplotlib import pyplot as plt\n",
                "from utils import plot_camera\n",
                "\n",
                "from tqdm.notebook import tqdm\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def Normalization(x):\n",
                "    x = np.asarray(x)\n",
                "    x = x / x[2, :]\n",
                "\n",
                "    m, s = np.mean(x, 1), np.std(x)\n",
                "    s = np.sqrt(2) / s\n",
                "\n",
                "    # TODO: compute the transformation matrix T\n",
                "    T = ...\n",
                "\n",
                "    xt = T @ x\n",
                "\n",
                "    return T, xt\n",
                "\n",
                "\n",
                "def fundamental_matrix(points1, points2):\n",
                "\n",
                "    # Normalize points in both images\n",
                "    T1, points1n = Normalization(points1)\n",
                "    T2, points2n = Normalization(points2)\n",
                "\n",
                "    # TODO: compute the fundamental matrix F\n",
                "    F = ...\n",
                "\n",
                "\n",
                "    return F"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <ul style=\"margin: 0; padding-left: 20px;\">\n",
                "    <strong>\ud83c\udfa5 Video Question 2:</strong><br>\n",
                "    <li>Why do we need to enforce the rank 2 constraint?<br>\n",
                "    <li>How do we enforce it?<br>\n",
                "  </ul>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The code below contains a toy example where we know the ground truth correspondences and ground-truth fundamental matrix. Use the code to test that the completed function is working properly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Two camera matrices for testing purposes\n",
                "P1 = np.zeros((3, 4))\n",
                "P1[0, 0] = P1[1, 1] = P1[2, 2] = 1\n",
                "angle = 15\n",
                "theta = np.radians(angle)\n",
                "c = np.cos(theta)\n",
                "s = np.sin(theta)\n",
                "R = np.array([[c, -s, 0], [s, c, 0], [0, 0, 1]])\n",
                "t = np.array([[0.3, 0.1, 0.2]])\n",
                "\n",
                "P2 = np.concatenate((R, t.T), axis=1)\n",
                "n = 8\n",
                "rand = np.random.uniform(0, 1, n)\n",
                "rand = rand.reshape((1, n))\n",
                "rand2 = np.random.uniform(0, 1, 2 * n)\n",
                "rand2 = rand2.reshape((2, n))\n",
                "ones = np.ones((1, n))\n",
                "X = np.concatenate((rand2, 3 * rand, ones), axis=0)\n",
                "\n",
                "x1_test = P1 @ X\n",
                "x2_test = P2 @ X\n",
                "\n",
                "# Estimate fundamental matrix (you need to create this function)\n",
                "logging.getLogger().setLevel(logging.DEBUG)  # For debugging purposes :)\n",
                "F_es = fundamental_matrix(x1_test, x2_test)\n",
                "logging.getLogger().setLevel(logging.INFO)  # Avoiding overprinting from now on :)\n",
                "\n",
                "\n",
                "# Ground truth fundamental matrix\n",
                "A = np.array([[0, -t[0, 2], t[0, 1]], [t[0, 2], 0, -t[0, 0]], [-t[0, 1], t[0, 0], 0]])\n",
                "F_gt = A @ R\n",
                "\n",
                "# Evaluation: these two matrices should be very similar\n",
                "F_gt = np.sign(F_gt[0, 0]) * F_gt / np.linalg.norm(F_gt)\n",
                "F_es = np.sign(F_es[0, 0]) * F_es / np.linalg.norm(F_es)\n",
                "dif_norm = np.linalg.norm(F_gt - F_es)\n",
                "logging.info(\n",
                "    (\"\\n\" * 2).join([f\"\\n\\nGround truth F: {F_gt}\", f\"Estimated F: {F_es}\", f\"Norm of the difference: {dif_norm}\"])\n",
                ")\n",
                "\n",
                "if dif_norm < 1e-5:\n",
                "    display(\n",
                "        Markdown(\n",
                "            '<span style=\"color: #00ff00\">The function `fundamental_matrix()` seems correct!<br>'\n",
                "            f\"Norm of the difference between estimated and ground truth matrix is {dif_norm:.3g}; i.e. almost zero.</span>\"\n",
                "        )\n",
                "    )\n",
                "else:\n",
                "    display(\n",
                "        Markdown(\n",
                "            '<span style=\"color: #ff0000\">The function `fundamental_matrix()` might be wrong!<br>'\n",
                "            f\"Norm of the difference between estimated and ground truth matrix is {dif_norm:.3g}; i.e. different from zero.</span>\"\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **1.2 Robust estimation of the fundamental matrix**\n",
                "\n",
                "The next step is to robustly compute the Fundamental matrix from the point correspondences. For that we will use the function `ransac_fundamental_matrix` that you have to complete.\n",
                "\n",
                "The next code computes the image correspondences."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read images\n",
                "img1_bgr = cv2.imread(\"Data/manikin1.jpg\", cv2.IMREAD_COLOR)\n",
                "img2_bgr = cv2.imread(\"Data/manikin2.jpg\", cv2.IMREAD_COLOR)\n",
                "img1_rgb = cv2.cvtColor(img1_bgr, cv2.COLOR_BGR2RGB)\n",
                "img2_rgb = cv2.cvtColor(img2_bgr, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "plt.figure(figsize=(15, 8))\n",
                "plt.suptitle(\"Images of the same object from different viewpoints\")\n",
                "for i, image in enumerate([img1_rgb, img2_rgb], start=1):\n",
                "    plt.subplot(1, 2, i)\n",
                "    plt.title(f\"Image {i}\")\n",
                "    plt.imshow(image)\n",
                "    plt.axis(\"off\")\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read images\n",
                "img1_gray = cv2.imread(\"Data/manikin1.jpg\", cv2.IMREAD_GRAYSCALE)\n",
                "img2_gray = cv2.imread(\"Data/manikin2.jpg\", cv2.IMREAD_GRAYSCALE)\n",
                "\n",
                "# Initiate SIFT detector\n",
                "sift = cv2.SIFT_create(3000)\n",
                "\n",
                "# find the keypoints and descriptors\n",
                "kp1, des1 = sift.detectAndCompute(img1_gray, None)\n",
                "kp2, des2 = sift.detectAndCompute(img2_gray, None)\n",
                "\n",
                "# Keypoint matching\n",
                "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
                "matches = bf.match(des1, des2)\n",
                "\n",
                "# Show matches\n",
                "img_12 = cv2.drawMatches(\n",
                "    img1_rgb, kp1, img2_rgb, kp2, matches, None, 12, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
                ")\n",
                "\n",
                "plt.figure(figsize=(18.5, 10.5))\n",
                "plt.title(\"SIFT correspondences between images\")\n",
                "plt.imshow(img_12)\n",
                "plt.axis(\"off\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <strong>\ud83c\udfa5 Video Question (Q3):</strong>\n",
                "  <ul>\n",
                "    <li>The function compute_inliers() is provided. How does it select the inliers?</li>\n",
                "  </ul>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "**Q4.** Complete the function `ransac_fundamental_matrix` below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_inliers(F, x1, x2, th):\n",
                "\n",
                "    Fx1 = F @ x1\n",
                "    Ftx2 = F.T @ x2\n",
                "\n",
                "    n = x1.shape[1]\n",
                "    x2tFx1 = np.zeros((1, n))\n",
                "\n",
                "    for i in range(n):\n",
                "        x2tFx1[0, i] = x2[:, i].T @ F @ x1[:, i]\n",
                "\n",
                "    # evaluate distances\n",
                "    den = Fx1[0, :] ** 2 + Fx1[1, :] ** 2 + Ftx2[0, :] ** 2 + Ftx2[1, :] ** 2\n",
                "    den = den.reshape((1, n))\n",
                "\n",
                "    d = x2tFx1**2 / den\n",
                "\n",
                "    inliers_indices = np.where(d[0, :] < th)\n",
                "\n",
                "    return inliers_indices[0]\n",
                "\n",
                "\n",
                "def ransac_fundamental_matrix(points1, points2, th, min_iterations):\n",
                "\n",
                "    Ncoords, Npts = points1.shape\n",
                "\n",
                "    p = 0.99\n",
                "    # TODO: Select the number of correspondences to sample\n",
                "    s = ...\n",
                "\n",
                "    it = 0\n",
                "    N = min_iterations\n",
                "    best_inliers = np.empty(1)\n",
                "    best_N = 1e16\n",
                "\n",
                "    # Initialize tqdm with dynamic total\n",
                "    pbar = tqdm(total=N, desc=\"RANSAC iterations\", unit=\"iter\")\n",
                "    \n",
                "    while it < N:\n",
                "\n",
                "        # TODO: Randomly select s correspondences to compute F and its inliers\n",
                "        inliers = ...\n",
                "\n",
                "\n",
                "        # update estimate of iterations (the number of trials) to ensure we pick, with probability p,\n",
                "        # an initial data set with no outliers\n",
                "        w = inliers.shape[0] / Npts\n",
                "        pOutlier = 1 - w**s\n",
                "        eps = sys.float_info.epsilon\n",
                "        pOutlier = max(eps, pOutlier)  # avoid log(0) that would cause a division by -Inf\n",
                "        pOutlier = min(1 - eps, pOutlier)  # avoid log(1) that would cause a division by 0\n",
                "        estimated_N = math.log(1 - p) / math.log(pOutlier)\n",
                "        best_N = min(best_N, estimated_N)  # Keep the best (lowest) N\n",
                "        N = max(min_iterations, best_N)  # Ensure at least min_iterations\n",
                "\n",
                "        # TODO: Update the best inliers\n",
                "\n",
                "        if len(inliers) == len(best_inliers):\n",
                "            print(f\"it:{it} - best inliers: {len(best_inliers)} - w: {w:.2f} - N: {N:.5g}\")\n",
                "\n",
                "        if int(N) > pbar.total:\n",
                "            pbar.total = int(N)\n",
                "            pbar.refresh()\n",
                "\n",
                "        pbar.update(1)\n",
                "        it += 1\n",
                "\n",
                "    pbar.close()\n",
                "\n",
                "    print(f\"Number of iterations: {it}, best inliers: {len(best_inliers)} - N: {N:.5g}\")\n",
                "\n",
                "    # Recompute F from all the inliers\n",
                "    F = fundamental_matrix(points1[:, best_inliers], points2[:, best_inliers])\n",
                "    inliers_recomputed = compute_inliers(F, points1, points2, th)\n",
                "    print(f\"Recomputed inliers: {len(inliers_recomputed)}\")\n",
                "\n",
                "    return F, best_inliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Robust estimation of the fundamental matrix\n",
                "points1 = []\n",
                "points2 = []\n",
                "for m in matches:\n",
                "    points1.append([kp1[m.queryIdx].pt[0], kp1[m.queryIdx].pt[1], 1])\n",
                "    points2.append([kp2[m.trainIdx].pt[0], kp2[m.trainIdx].pt[1], 1])\n",
                "\n",
                "points1 = np.asarray(points1)\n",
                "points1 = points1.T\n",
                "points2 = np.asarray(points2)\n",
                "points2 = points2.T\n",
                "\n",
                "F, indices_inlier_matches = ransac_fundamental_matrix(points1, points2, th=2, min_iterations=5000)\n",
                "inlier_matches = [matches[i] for i in indices_inlier_matches]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "img_12 = cv2.drawMatches(\n",
                "    img1_rgb, kp1, img2_rgb, kp2, inlier_matches, None, 12, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
                ")\n",
                "plt.figure(figsize=(18.5, 10.5))\n",
                "plt.title(\"Inliers of SIFT correspondences based on the estimated fundamental matrix (F)\")\n",
                "plt.imshow(img_12)\n",
                "plt.axis(\"off\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **1.3 Epipolar lines**\n",
                "\n",
                "We will now visualize the epipolar lines associated to some points.\n",
                "\n",
                "**Q5.** Choose 3 inlier points in the first image and compute their corresponding epipolar lines (in homogeneous coordinates) in the second image. Do the same but now choosing points in the second image and showing their epipolar lines in the first image. Provide the commands you used for that. The commands for showing the lines on top of the image are already provided."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: compute the epipolar lines\n",
                "l2 = ... # epipolar lines in image 2\n",
                "l1 = ... # epipolar lines in image 1\n",
                "\n",
                "# choose three random indices\n",
                "N = indices_inlier_matches.shape[0]\n",
                "indices = random.sample(range(1, N), 3)\n",
                "\n",
                "selected_indices = indices_inlier_matches[indices]\n",
                "\n",
                "\n",
                "# Function required to display lines\n",
                "def get_line_points(l, I):\n",
                "    x = np.arange(0, np.array(I).shape[1])\n",
                "    y = (-l[0] * x - l[2]) / l[1]\n",
                "    return x, y\n",
                "\n",
                "\n",
                "# Display image with epipolar lines and points\n",
                "plt.figure(figsize=(18.5, 10.5))\n",
                "points_color = \"black\"\n",
                "for num_plot, (image, epipolar_lines, points) in enumerate(\n",
                "    zip([img1_rgb, img2_rgb], [l1, l2], [points1, points2]), start=1\n",
                "):\n",
                "    plt.subplot(1, 2, num_plot)\n",
                "    plt.title(f\"Image {num_plot} with points and computed epipolar lines\")\n",
                "    for i, index in enumerate(selected_indices, start=1):\n",
                "        plt.plot(*get_line_points(epipolar_lines[:, index], image), label=f\"$l{chr(39) * (num_plot == 2)}_{i}$\")\n",
                "\n",
                "    for i, (x, y) in enumerate(zip(points[0, selected_indices], points[1, selected_indices]), start=1):\n",
                "        plt.scatter(x=x, y=y, c=points_color, s=30)\n",
                "        plt.text(\n",
                "            x,\n",
                "            y,\n",
                "            f\"$x{chr(39) * (num_plot == 2)}_{i}$\",\n",
                "            fontsize=20,\n",
                "            ha=\"right\",\n",
                "            va=\"bottom\",\n",
                "            color=points_color,\n",
                "            weight=\"bold\",\n",
                "        )\n",
                "    plt.imshow(image)\n",
                "    plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <strong>\ud83c\udfa5 Video Question (Q5b):</strong>\n",
                "  <ul>\n",
                "    <li>How did you obtain the epipolar lines?</li>\n",
                "    <li>Where do they intersect?</li>\n",
                "  </ul>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Q6.** First, compute the epipoles from the Fundamental matrix. Then, compute the epipolar lines as the line that passes through the matching point and the epipole. Check that you obtain the same epipolar lines as before."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "##SOLUTION\n",
                "# # Epipole of the first image\n",
                "U, d, Vt = np.linalg.svd(F)\n",
                "epipole1 = Vt[-1, :]\n",
                "print(f\"Epipole first image (from fundamental matrix): {epipole1}\")\n",
                "epipole1_intersetion = np.cross(l1[:, 10], l1[:, 121])\n",
                "epipole1_intersetion /= np.linalg.norm(epipole1_intersetion)\n",
                "print(f\"Epipole first image (from intersection of epipolar lines): {epipole1_intersetion}\")\n",
                "\n",
                "line_1 = l1[:, 2]\n",
                "print(f\"Epipolar line 1: {line_1 / line_1[-1]}\")\n",
                "line1_intersection = np.cross(epipole1, points1[:, 2])\n",
                "print(f\"Epipolar line 1: {line1_intersection / line1_intersection[-1]}\")\n",
                "\n",
                "print(\"\\n\\n\")\n",
                "\n",
                "# Epipole of the second image\n",
                "U, d, Vt = np.linalg.svd(F.T)\n",
                "epipole2 = Vt[-1, :]\n",
                "print(f\"Epipole second image (from fundamental matrix): {epipole2}\")\n",
                "epipole2_intersetion = np.cross(l2[:, 10], l2[:, 121])\n",
                "epipole2_intersetion /= np.linalg.norm(epipole2_intersetion)\n",
                "print(f\"Epipole second image (from intersection of epipolar lines): {epipole2_intersetion}\")\n",
                "\n",
                "line_2 = l2[:, 456]\n",
                "print(f\"Epipolar line 2: {line_2 / line_2[-1]}\")\n",
                "line2_intersection = np.cross(epipole2, points2[:, 456])\n",
                "print(f\"Epipolar line 2: {line2_intersection / line2_intersection[-1]}\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <strong>\ud83c\udfa5 Video Question (Q6b):</strong>\n",
                "  <ul>\n",
                "    <li>Explain the previous cell. Why does it work?</li>\n",
                "  </ul>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Structure computation\n",
                "\n",
                "### **2.1 Triangulation**\n",
                "\n",
                "Before recovering the camera motion, we will first need to implement a function to triangulate matches.  This is a function that takes as input a match and the projection matrices of two cameras, and computes the 3D position of a match.\n",
                "\n",
                "We want then to find the 3D point $\\mathbf{X}$ such that its projection onto the images are $\\mathbf{x} = P \\mathbf{X}$ and $\\mathbf{x'} = P' \\mathbf{X}$ (being $P$ and $P'$ the projection matrices of each camera).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Q7.** Derive the expression of matrix $A$ in the system of equations in algebraic form, $A \\mathbf{X} = \\mathbf{0}$, that we need to solve in order to estimate the homogeneous coordinates of the 3D point $\\mathbf{X}$."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Answer here. You can write it on a paper and show a picture here, or write it in LaTex.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <strong>\ud83c\udfa5 Video Question (Q7b):</strong>\n",
                "  <ul>\n",
                "    <li>Explain the theoretical solution above</li>\n",
                "  </ul>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "**Q8.** Complete the code of the `triangulate`function below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def triangulate(x1, x2, P1, P2, imsize):\n",
                "\n",
                "    # only one point\n",
                "    if x1.ndim == 1:\n",
                "        x1 = np.array([x1]).T\n",
                "        x2 = np.array([x2]).T\n",
                "\n",
                "    # number of points\n",
                "    n = x1.shape[1]\n",
                "\n",
                "    # Normalization\n",
                "    x1 = x1 / x1[2, :]\n",
                "    x2 = x2 / x2[2, :]\n",
                "\n",
                "    nx = imsize[0]\n",
                "    ny = imsize[1]\n",
                "\n",
                "    H = [[2 / nx, 0, -1], [0, 2 / ny, -1], [0, 0, 1]]\n",
                "\n",
                "    x1_norm = H @ x1\n",
                "    x2_norm = H @ x2\n",
                "    P1_norm = H @ P1\n",
                "    P2_norm = H @ P2\n",
                "\n",
                "    # TODO: compute the triangulated points\n",
                "    X = ...\n",
                "\n",
                "\n",
                "    return X"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You may use the following test code with a toy example to validate that the `triangulate`function is working properly.\n",
                "In summary, this code simulates the process of 3D point projection, triangulation, and evaluation of the reprojection error in a scenario with two cameras and randomly generated 3D points."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Camera Matrices\n",
                "# P1 is initialized as the identity matrix (3x4)\n",
                "P1 = np.eye(3, 4)\n",
                "\n",
                "# P2 is generated by applying a rotation of 15 degrees around the z-axis and a translation\n",
                "angle = 15\n",
                "theta = np.radians(angle)\n",
                "c = np.cos(theta)\n",
                "s = np.sin(theta)\n",
                "R = np.array([[c, -s, 0], [s, c, 0], [0, 0, 1]])\n",
                "t = np.array([[0.3, 0.1, 0.2]])\n",
                "P2 = np.concatenate((R, t.T), axis=1)\n",
                "\n",
                "# Generate n random 3D Points\n",
                "# Each point is represented as a homogeneous 4D vector\n",
                "n = 8\n",
                "rand = np.random.uniform(0, 1, n).reshape((1, n))\n",
                "rand2 = np.random.uniform(0, 1, 2 * n).reshape((2, n))\n",
                "ones = np.ones((1, n))\n",
                "X = np.concatenate((rand2, 3 * rand, ones), axis=0)\n",
                "\n",
                "# Project 3D Points\n",
                "# 3D points are projected onto the image planes of the two cameras\n",
                "x1_test = P1 @ X\n",
                "x2_test = P2 @ X\n",
                "\n",
                "# Estimate the 3D points (you need to create this function)\n",
                "# The function triangulate() is called to estimate the 3D coordinates of the points using the corresponding 2D points and camera matrices\n",
                "x_trian = triangulate(x1_test, x2_test, P1, P2, ((2, 2)))\n",
                "\n",
                "# Evaluation: compute the reprojection error\n",
                "# The synthetic 3D points (X_eucl) and the triangulated 3D points (x_eucl) are converted from homogeneous coordinates to Euclidean coordinates.\n",
                "x_eucl = x_trian / x_trian[3, :]\n",
                "X_eucl = X / X[3, :]\n",
                "# The difference between these two sets of points is computed and printed as the reprojection error.\n",
                "reproj_err = np.linalg.norm(X_eucl - x_eucl, axis=0)\n",
                "print(f\"Reprojection error for n={n} points:\", reproj_err, sep=\"\\n\", end=\"\\n\" * 2)\n",
                "if np.allclose(reproj_err, 0, atol=1e-5):\n",
                "    display(Markdown('<span style=\"color: #00ff00\">The function `triangulate()` seems correct!</span>'))\n",
                "else:\n",
                "    display(Markdown('<span style=\"color: #ff0000\">The function `triangulate()` might be wrong!</span>'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Relative motion between the two cameras\n",
                "As seen in the theory class, the relative position between the cameras can be computed from the Essential matrix, $E$. In order to estimate $E$, we need the Fundamental matrix, $F$, that we have just computed and the camera calibration matrix, $K$, that we learnt how to estimate during the second lab.\n",
                "\n",
                "**Q9.** Compute the Essential matrix from the Fundamental matrix and the camera calibration matrix in the code below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# K matrix estimated as in lab 2\n",
                "K = np.array([[3531.97, 9.59, 2304.33], [0, 3537.34, 1751.75], [0, 0, 1]])\n",
                "\n",
                "# TODO: Complete the essential matrix\n",
                "E = ...\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will assume that the first camera is at the origin, with no rotation, and that the second camera has a rotation and translation with respect to the first one.\n",
                "\n",
                "**Q10.** Write the camera projection matrix $P$ for the first camera."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Compute the projection matrix of the first camera\n",
                "P1 = ...\n",
                "\n",
                "print(P1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The rotation and translation of the second camera can be computed from the SVD decomposition of $E$. There are four possible solutions.\n",
                "\n",
                "**Q11.** Complete the code below to compute the four candidate solutions for the second camera projection matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "U, D, Vt = np.linalg.svd(E)\n",
                "\n",
                "# The SVD of E has several ambiguities. In particular, U and V may be\n",
                "# improper rotations in which case we need to change their sign.\n",
                "if np.linalg.det(U) < 0:\n",
                "    U = -U\n",
                "\n",
                "if np.linalg.det(Vt) < 0:\n",
                "    Vt = -Vt\n",
                "\n",
                "\n",
                "# TODO: Find the four potential camera projection matrices for the second camera\n",
                "Pc2 = np.empty(shape=(4, 3, 4))\n",
                "Pc2[0] = ...\n",
                "Pc2[1] = ...\n",
                "Pc2[2] = ...\n",
                "Pc2[3] = ...\n",
                "\n",
                "ny, nx, _ = img1_rgb.shape\n",
                "\n",
                "fig = go.Figure()\n",
                "plot_camera(P1, nx, ny, fig, \"Reference camera\")\n",
                "for i in range(4):\n",
                "    plot_camera(Pc2[i], nx, ny, fig, f\"Camera_2-Option_{i+1}\")\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting the proper camera projection matrix"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <strong>\ud83c\udfa5 Video Question (Q12):</strong>\n",
                "  <ul>\n",
                "    <li>How can we choose the right solution from the four candidates? The code to do it is provided below, explain how it works.</li>\n",
                "  </ul>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x1 = points1[:, indices_inlier_matches]\n",
                "x2 = points2[:, indices_inlier_matches]\n",
                "\n",
                "for P2i in Pc2:\n",
                "\n",
                "    Xi = triangulate(x1[:, 0], x2[:, 0], P1, P2i, [nx, ny])\n",
                "    Xi = Xi / Xi[3, :]\n",
                "\n",
                "    x1est = P1 @ Xi\n",
                "    x2est = P2i @ Xi\n",
                "\n",
                "    if (x1est[2] > 0) and (x2est[2] > 0):\n",
                "        P2 = P2i\n",
                "        break\n",
                "\n",
                "fig = go.Figure()\n",
                "plot_camera(P1, nx, ny, fig, \"Camera 1\")\n",
                "plot_camera(P2, nx, ny, fig, \"Camera 2\")\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **2.3 Reconstruction from two views**\n",
                "\n",
                "Once the proper solution for the relative motion between cameras is chosen, we can triangulate all the matches to get a sparse point cloud. \n",
                "\n",
                "**Q13.** Complete the code to triangulate all matches.\n",
                "\n",
                "Use the provided code to plot the reconstructed points. If everything went fine, you should recognize the sparse points corresponding to the different parts of the manikin body at their corresponding 3D positions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Triangulate all matches\n",
                "X = ...\n",
                "\n",
                "# Render the 3D point cloud\n",
                "fig = go.Figure()\n",
                "plot_camera(P1, nx, ny, fig, \"Camera 1\")\n",
                "plot_camera(P2, nx, ny, fig, \"Camera 2\")\n",
                "x_img = x1[:2].T.astype(int)\n",
                "rgb_vals = img1_rgb[x_img[:, 1], x_img[:, 0]]\n",
                "# rgb_vals = [f\"rgb{tuple(x)}\" for x in rgb_vals]\n",
                "rgb_vals = [f\"rgb({int(r)},{int(g)},{int(b)})\" for r, g, b in rgb_vals]\n",
                "\n",
                "\n",
                "point_color = [(255, 0, 0), (0, 255, 0)]\n",
                "fig.add_trace(go.Scatter3d(x=X[0, :], y=X[2, :], z=-X[1, :], mode=\"markers\", marker=dict(size=2, color=rgb_vals)))\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, we are going to compute the reprojection error of the reconstructed points.  This is the distance between the detected keypoints, `x1` and `x2`, and the projection of the reconstructed points.\n",
                "\n",
                "**Q14.** Complete the code to compute the reprojection error of each match. Plot the histogram of the errors with the provided code. Explain the result."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def reprojection_errors(x1, x2, P1, P2, X):\n",
                "\n",
                "    # ... complete\n",
                "\n",
                "    return (err1 + err2) / 2\n",
                "\n",
                "\n",
                "err = reprojection_errors(x1, x2, P1, P2, X)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set_theme(style=\"whitegrid\")\n",
                "ax = sns.displot(err, kde=True, bins=10)\n",
                "mean_err = np.mean(err)\n",
                "plt.axvline(x=mean_err, color='r', linestyle='--', label=f'Mean: {mean_err:.2f} pixels')\n",
                "plt.title(\"Histogram and Distribution of Reprojection Errors\")\n",
                "plt.xlabel(\"Reprojection Error (pixels)\")\n",
                "plt.ylabel(\"Counts / Density\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <strong>\ud83c\udfa5 Video Question (Q14):</strong>\n",
                "  <ul>\n",
                "    <li>Interpret the results of the reprojection error above.</li>\n",
                "  </ul>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. References"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Add here the material you used to complete this Lab. Cite and describe the usage of AI tools if any was used according to the Guidelines for AI tools."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "TODO: Complete"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <strong>\ud83c\udfa5 Video Questions</strong>: Briefly mention the references.\n",
                "</div>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"border: 2px solid #007acc; border-radius: 10px; padding: 10px; background-color: #e6f2ff;\">\n",
                "  <strong>\ud83c\udfa5 Self-Assessment and Conclusions</strong>:\n",
                "  <ul>\n",
                "  <li><b>Which parts of the notebook did you succeed in? </b><br>\n",
                "  <em>Describe the sections where you felt confident, and explain why you think they were successful.</em></li>\n",
                "  <li><b>Which parts of the notebook did you fail to solve? </b><br>\n",
                "  <em>Be honest about the areas where you faced difficulties. What challenges or issues did you encounter that you couldn\u2019t resolve? How would you approach these issues in the future?</em></li>\n",
                "  </ul>\n",
                "  Is there anything else that you would like to comment?\n",
                "</div>\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "3d_vision",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}